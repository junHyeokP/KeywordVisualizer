# 키워드 기반 시각화 프로젝트

# 소개

**KeywordVisualizer**

csv 파일 내용 내 주요 키워드를 뽑아서 워드클라우드나 막대기 그래프로 보여주는 프로젝트입니다.

Streamlit으로 동작하며, csv 파일을 업로드 하고 "분석 시작" 버튼을 눌러 검색 주제를 변경할 수 있습니다.

네이버 API를 이용한 웹크롤링을 거쳐 생성된 .csv 확장자의 파일이 필요합니다.

# 시스템 구성

**Python** : 고수준 인터프리터 코딩 언어, 3.10버전 사용 

**Streamlit** : 데이터 분석과 시각화를 함께 구성할 수 있는 파이썬 오픈 소스 라이브러리

**scikit-learn** : 분류, 회귀와 같은 단순하고 널리 알려진 전통 알고리즘 분석 기능을 포함한 머신러닝 라이브러리 

**scikit-learn matplotlib** : 데이터 분석 시각화 파이썬 오픈소스 라이브러리, 워드 클라우드, 바 그래프를 사용

**konlpy** : 한국어 텍스트 정보처리를 위한 NLP(Natural Language Processing) 파이썬 패키지

# 시스템 흐름 설명

1. CSV 파일 입력
사용자는 네이버 API를 통해 수집된 .csv 확장자의 텍스트 데이터를 업로드한다.
이 데이터는 뉴스 기사, 블로그 글, 사용자 리뷰 등 키워드 분석이 가능한 형태의 텍스트로 구성되어 있어야 한다.

2. 텍스트 전처리 (Preprocessing)
업로드된 CSV 파일의 텍스트 데이터는 다음과 같은 전처리 과정을 거친다:

형태소 분석:
konlpy 라이브러리의 Okt, Komoran, Kkma 등의 형태소 분석기를 활용해 문장을 단어 단위로 분해한다.

불용어 제거:
의미 없는 조사나 접속사 등 분석에 필요 없는 단어를 제거한다.
이 단계는 정확한 키워드 추출을 위해 필수적이다.

명사 추출:
형태소 분석 결과 중 명사만을 추출하여 키워드 후보군을 생성한다.

3. 키워드 빈도 분석
전처리된 단어 리스트를 기반으로, scikit-learn의 CountVectorizer 또는 collections.Counter를 활용하여
단어별 등장 빈도를 계산한다. 이는 시각화의 기반 데이터가 된다.

4. 시각화 (Visualization)
사용자는 원하는 시각화 유형을 선택할 수 있으며, 다음과 같은 방식으로 출력된다:

워드 클라우드 (Word Cloud)
키워드의 빈도에 비례하는 크기로 단어를 시각화한다.
wordcloud 라이브러리를 사용하여 형태학적으로 의미 있는 키워드를 부각한다.

막대 그래프 (Bar Graph)
상위 N개의 키워드를 막대 형태로 시각화한다.
matplotlib를 이용하여 분석 결과의 직관적 해석을 돕는다.

5. Streamlit UI 구성
파일 업로드 기능: 사용자가 .csv 파일을 선택하여 업로드할 수 있다.

분석 시작 버튼: 클릭 시 분석이 자동으로 실행된다.

시각화 옵션 선택: 워드 클라우드 또는 바 그래프를 선택할 수 있는 옵션 제공(두 그래프를 동시에 키는 것이 가능).

결과 출력 영역: 시각화 결과 이미지와 키워드 통계를 Streamlit 화면에 출력.
